# parts_bom_streamlit_app.py
# --- BOM Builder å®Œå…¨ç‰ˆ (Python + Streamlit) ---
# è¦ä»¶ã¾ã¨ã‚ï¼ˆ2025-08-30ï¼‰
# 1) DB(éƒ¨å“ã‚«ã‚¿ãƒ­ã‚°)ã®ä½œæˆ/æ›´æ–°ï¼šSQLite
# 2) å¤šæ§˜ãªè³‡æ–™ã‹ã‚‰å–ã‚Šè¾¼ã¿ï¼šCSV/Excel/ãƒ†ã‚­ã‚¹ãƒˆï¼ˆPDFã¯ä»»æ„ï¼‰
# 3) DBã‚’å‚ç…§ã—ã¦BOMä½œæˆ/å‡ºåŠ›
# 4) é‹ç”¨:
#    - èµ·å‹•æ™‚ã«æ—¢å­˜DB/ãƒã‚¹ã‚¿ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡ºï¼ˆparts_master.xlsx/csvï¼‰
#    - å–ã‚Šè¾¼ã¿ã¯ã€Œå€™è£œâ†’ç¢ºèªâ†’ç¢ºå®šã€2æ®µéš
#    - DBæ›´æ–°ã‚„BOMæ“ä½œã®å‰ã«è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
# 5) UI:
#    - ã‚«ãƒ†ã‚´ãƒª1/2ãƒãƒ«ãƒã‚»ãƒ¬ã‚¯ãƒˆã§çµã‚Šè¾¼ã¿
#    - è¡Œãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã§è¤‡æ•°ä¸€æ‹¬é¸æŠâ†’BOMã¸è¿½åŠ 
#    - ä¾¡æ ¼ãƒ¢ãƒ‡ãƒ«: fixed / per_kwh / per_year
#      â†’ BOMç”»é¢ã§å®¹é‡(kWh)ãƒ»å¹´æ•°(years)ã‚’å…¥åŠ›ã—ã¦é‡‘é¡è‡ªå‹•è¨ˆç®—
# 6) EMS:
#    - Software license ã®ä¾¡æ ¼ã®ã¿æ¡ç”¨ï¼ˆper_kwhã«è½ã¨ã—è¾¼ã‚€æƒ³å®šï¼‰
#    - notes è‡ªå‹•è£œåŠ©ï¼ˆEMSé–¢é€£ã®æ–‡ã‚’è¦ç´„ï¼‰â€»CSV/Excelã§ã¯ãã®ã¾ã¾

import io
import os
import re
import shutil
import sqlite3
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import pandas as pd
import streamlit as st

DB_PATH = "parts_bom.db"
MASTER_CANDIDATES = ["parts_master.xlsx", "parts_master.csv"]
BACKUP_DIR = Path("_db_backups")

PART_COLS = [
    "partNo","description","manufacturer","category",
    "unit","unitPrice","notes",
    "category1","category2","pricingModel",
    "unitPricePerKWh","unitPricePerYear","refCapacityKWh",
]

CREATE_SQL = {
    "parts": """
        CREATE TABLE IF NOT EXISTS parts (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            partNo TEXT NOT NULL,
            description TEXT,
            manufacturer TEXT,
            category TEXT,
            unit TEXT,
            unitPrice REAL,
            notes TEXT,
            category1 TEXT,
            category2 TEXT,
            pricingModel TEXT DEFAULT 'fixed',
            unitPricePerKWh REAL,
            unitPricePerYear REAL,
            refCapacityKWh REAL
        );
    """,
    "boms": """
        CREATE TABLE IF NOT EXISTS boms (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT NOT NULL,
            createdAt INTEGER NOT NULL
        );
    """,
    "bom_items": """
        CREATE TABLE IF NOT EXISTS bom_items (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            bomId INTEGER NOT NULL,
            partId INTEGER NOT NULL,
            qty REAL NOT NULL DEFAULT 1,
            altText TEXT,
            FOREIGN KEY (bomId) REFERENCES boms(id) ON DELETE CASCADE,
            FOREIGN KEY (partId) REFERENCES parts(id) ON DELETE CASCADE
        );
    """,
}

def get_conn():
    return sqlite3.connect(DB_PATH, check_same_thread=False)

def init_db():
    with get_conn() as con:
        cur = con.cursor()
        for sql in CREATE_SQL.values():
            cur.execute(sql)
        con.commit()

def backup_db_file() -> Optional[Path]:
    dbp = Path(DB_PATH)
    if not dbp.exists():
        return None
    BACKUP_DIR.mkdir(parents=True, exist_ok=True)
    ts = datetime.now().strftime("%Y%m%d-%H%M%S")
    dst = BACKUP_DIR / f"{dbp.stem}.backup-{ts}{dbp.suffix}"
    shutil.copy2(dbp, dst)
    return dst

def count_parts() -> int:
    with get_conn() as con:
        cur = con.cursor()
        cur.execute("SELECT COUNT(*) FROM parts")
        (n,) = cur.fetchone()
        return int(n or 0)

def find_master_file() -> Optional[Path]:
    for name in MASTER_CANDIDATES:
        p = Path(name)
        if p.exists():
            return p
    return None

def load_master_to_df(p: Path) -> pd.DataFrame:
    if p.suffix.lower() == ".csv":
        return pd.read_csv(p)
    return pd.read_excel(p)

HEADER_GUESS_PATTERNS: List[Tuple[str, str]] = [
    (r"^part\s*no|^pn$|^å“ç•ª|^éƒ¨å“ç•ªå·", "partNo"),
    (r"^desc|^description|^ä»•æ§˜|^åç§°|^å“å|^å†…å®¹", "description"),
    (r"^maker|^manufacturer|^è£½é€ |^ãƒ¡ãƒ¼ã‚«ãƒ¼", "manufacturer"),
    (r"^cat$|^category|^åˆ†é¡|^ã‚«ãƒ†ã‚´ãƒª$", "category"),
    (r"^category1|^ã‚«ãƒ†ã‚´ãƒª1", "category1"),
    (r"^category2|^ã‚«ãƒ†ã‚´ãƒª2", "category2"),
    (r"^unit|^å˜ä½", "unit"),
    (r"^price|^å˜ä¾¡|^unit\s*price|^cost", "unitPrice"),
    (r"^note|^å‚™è€ƒ|^comment", "notes"),
    (r"pricing|price\s*model|ä¾¡æ ¼.*ãƒ¢ãƒ‡ãƒ«", "pricingModel"),
    (r"per\s*kwh|unitPricePerKWh", "unitPricePerKWh"),
    (r"per\s*year|unitPricePerYear", "unitPricePerYear"),
]

def guess_field(header: str) -> Optional[str]:
    h = str(header).strip().lower()
    for pat, key in HEADER_GUESS_PATTERNS:
        if re.search(pat, h):
            return key
    return None

def parse_free_text(text: str) -> pd.DataFrame:
    lines = [l.strip() for l in text.splitlines() if l.strip()]
    rows = []
    for line in lines:
        cols = re.split(r"\t+|\s{2,}", line)
        if len(cols) >= 2:
            part_no = cols[0]
            desc = cols[1]
            rows.append({
                "partNo": part_no,
                "description": desc,
                "manufacturer": "",
                "category": "",
                "unit": "set",
                "unitPrice": None,
                "notes": "",
                "category1": "",
                "category2": "",
                "pricingModel": "fixed",
                "unitPricePerKWh": None,
                "unitPricePerYear": None,
                "refCapacityKWh": None,
            })
    return pd.DataFrame(rows, columns=PART_COLS)

def insert_parts(df: pd.DataFrame) -> int:
    if not set(PART_COLS).issubset(df.columns):
        for c in PART_COLS:
            if c not in df.columns:
                df[c] = None if c not in ["manufacturer","category","unit","notes","category1","category2","pricingModel"] else ""
    if not st.session_state.get("allow_update", False):
        if not st.checkbox("ã“ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§DBæ›´æ–°ã‚’è¨±å¯ã™ã‚‹ï¼ˆç¢ºèªç”¨ï¼‰"):
            st.warning("ãƒã‚§ãƒƒã‚¯ã‚’å…¥ã‚Œã‚‹ã¨DBæ›´æ–°ãŒæœ‰åŠ¹ã«ãªã‚Šã¾ã™ã€‚")
            return 0
        st.session_state["allow_update"] = True

    with get_conn() as con:
        df = df.copy()
        df["unitPrice"] = pd.to_numeric(df["unitPrice"], errors="coerce")
        df["unitPricePerKWh"] = pd.to_numeric(df["unitPricePerKWh"], errors="coerce")
        df["unitPricePerYear"] = pd.to_numeric(df["unitPricePerYear"], errors="coerce")
        exist = pd.read_sql_query("SELECT partNo, description FROM parts", con)
        if not exist.empty:
            key_new = (df["partNo"].str.lower()+"|"+df["description"].str.lower())
            key_exist = (exist["partNo"].str.lower()+"|"+exist["description"].str.lower()).tolist()
            df = df[~key_new.isin(key_exist)]
        if df.empty:
            return 0
        df[PART_COLS].to_sql("parts", con, if_exists="append", index=False)
        return len(df)

def read_parts(q: str = "") -> pd.DataFrame:
    with get_conn() as con:
        base = """
        SELECT id, partNo, description, manufacturer, category, category1, category2,
               unit, unitPrice, pricingModel, unitPricePerKWh, unitPricePerYear, refCapacityKWh, notes
        FROM parts
        """
        if q:
            like = f"%{q}%"
            return pd.read_sql_query(
                base + """ WHERE partNo LIKE ? OR description LIKE ? OR manufacturer LIKE ?
                           OR category LIKE ? OR category1 LIKE ? OR category2 LIKE ?
                           OR unit LIKE ? OR notes LIKE ?""",
                con, params=[like, like, like, like, like, like, like, like],
            )
        return pd.read_sql_query(base, con)

def delete_part(part_id: int):
    with get_conn() as con:
        con.execute("DELETE FROM parts WHERE id = ?", (part_id,))
        con.commit()

def create_bom(name: str) -> int:
    with get_conn() as con:
        cur = con.cursor()
        cur.execute("INSERT INTO boms(name, createdAt) VALUES(?, ?)", (name, int(time.time()*1000)))
        con.commit()
        return cur.lastrowid

def list_boms() -> pd.DataFrame:
    with get_conn() as con:
        return pd.read_sql_query("SELECT * FROM boms ORDER BY createdAt DESC", con)

def list_bom_items(bom_id: int) -> pd.DataFrame:
    with get_conn() as con:
        sql = """
        SELECT bi.id as itemId, bi.bomId, bi.partId, bi.qty, bi.altText,
               p.partNo, p.description, p.manufacturer,
               p.category, p.category1, p.category2,
               p.unit, p.unitPrice,
               p.pricingModel, p.unitPricePerKWh, p.unitPricePerYear, p.refCapacityKWh, p.notes
        FROM bom_items bi
        JOIN parts p ON p.id = bi.partId
        WHERE bi.bomId = ?
        ORDER BY bi.id ASC
        """
        return pd.read_sql_query(sql, con, params=[bom_id])

def add_item(bom_id: int, part_id: int, qty: float = 1.0):
    with get_conn() as con:
        con.execute("INSERT INTO bom_items(bomId, partId, qty) VALUES(?, ?, ?)", (bom_id, part_id, qty))
        con.commit()

def remove_item(item_id: int):
    with get_conn() as con:
        con.execute("DELETE FROM bom_items WHERE id = ?", (item_id,))
        con.commit()

def update_qty(item_id: int, qty: float):
    with get_conn() as con:
        con.execute("UPDATE bom_items SET qty = ? WHERE id = ?", (qty, item_id))
        con.commit()

# -------- Streamlit App --------
st.set_page_config(page_title="BOM Builder", page_icon="ğŸ§©", layout="wide")
init_db()

st.sidebar.header("èµ·å‹•æ™‚ã®èª­ã¿è¾¼ã¿")
parts_count = count_parts()
master = find_master_file()
if master is not None:
    st.sidebar.success(f"ãƒã‚¹ã‚¿ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º: {master.name}")
    st.sidebar.caption(f"æœ€çµ‚æ›´æ–°: {datetime.fromtimestamp(Path(master).stat().st_mtime):%Y-%m-%d %H:%M:%S}")
    if parts_count == 0:
        if st.sidebar.button("ã“ã®ãƒã‚¹ã‚¿ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"):
            try:
                dfm = load_master_to_df(master)
                all_cols = list(dfm.columns)
                mapping = {}
                for key in PART_COLS:
                    if key in dfm.columns:
                        mapping[key] = key
                    else:
                        guessed = next((c for c in all_cols if guess_field(str(c)) == key), None)
                        mapping[key] = guessed
                df_norm = pd.DataFrame({k: (dfm[mapping[k]] if mapping[k] else "") for k in PART_COLS})
                df_norm["unitPrice"] = pd.to_numeric(df_norm["unitPrice"], errors="coerce")
                n = insert_parts(df_norm)
                st.sidebar.success(f"{n} ä»¶ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
            except Exception as e:
                st.sidebar.error(f"èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
else:
    st.sidebar.info("parts_master.xlsx / parts_master.csv ã‚’åŒã˜ãƒ•ã‚©ãƒ«ãƒ€ã«ç½®ãã¨è‡ªå‹•æ¤œå‡ºã—ã¾ã™ã€‚")

st.sidebar.header("ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—")
if Path(DB_PATH).exists():
    if st.sidebar.button("DBã‚’æ‰‹å‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"):
        dst = backup_db_file()
        if dst:
            st.sidebar.success(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: {dst}")
else:
    st.sidebar.caption("DBãƒ•ã‚¡ã‚¤ãƒ«æœªä½œæˆï¼ˆã¾ã ãƒ‡ãƒ¼ã‚¿æœªä¿å­˜ï¼‰")

st.title("éƒ¨å“è¡¨ãƒ–ãƒ©ã‚¦ã‚¶ã‚¢ãƒ—ãƒªï¼ˆå®Œå…¨ç‰ˆï¼‰")
TAB_DB, TAB_INGEST, TAB_BOM = st.tabs(["ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹", "è³‡æ–™å–ã‚Šè¾¼ã¿", "BOM ä½œæˆ"])

with TAB_DB:
    st.subheader("æ¤œç´¢ãƒ»ä¸€è¦§")
    q = st.text_input("ãƒ•ãƒªãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆå“ç•ªãƒ»å“åãƒ»ã‚«ãƒ†ã‚´ãƒª1/2ãƒ»å‚™è€ƒâ€¦ï¼‰", value="")
    df_all = read_parts(q)

    for c in ["category1","category2","pricingModel","unit"]:
        if c in df_all.columns:
            df_all[c] = df_all[c].fillna("")

    cat1_options = sorted([c for c in df_all["category1"].unique().tolist() if c])
    cat2_options = sorted([c for c in df_all["category2"].unique().tolist() if c])

    c1, c2 = st.columns(2)
    with c1:
        sel_c1 = st.multiselect("ã‚«ãƒ†ã‚´ãƒª1ã§çµã‚Šè¾¼ã¿ï¼ˆè¤‡æ•°å¯ï¼‰", options=cat1_options, default=[])
    with c2:
        sel_c2 = st.multiselect("ã‚«ãƒ†ã‚´ãƒª2ã§çµã‚Šè¾¼ã¿ï¼ˆè¤‡æ•°å¯ï¼‰", options=cat2_options, default=[])

    df_view = df_all.copy()
    if sel_c1:
        df_view = df_view[df_view["category1"].isin(sel_c1)]
    if sel_c2:
        df_view = df_view[df_view["category2"].isin(sel_c2)]

    if "_select" not in df_view.columns:
        df_view.insert(0, "_select", False)

    st.caption("BOMã«è¿½åŠ ã—ãŸã„è¡Œã«ãƒã‚§ãƒƒã‚¯ã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚")
    edited = st.data_editor(
        df_view[["_select","id","partNo","description","category1","category2",
                 "pricingModel","unit","unitPrice","unitPricePerKWh","unitPricePerYear","notes"]],
        use_container_width=True, height=450, hide_index=True
    )
    selected_ids = edited.loc[edited["_select"] == True, "id"].astype(int).tolist()
    st.session_state["selected_part_ids"] = selected_ids

    st.markdown("---")
    st.subheader("æ–°è¦ãƒ‘ãƒ¼ãƒ„è¿½åŠ ï¼ˆä»»æ„ï¼‰")
    with st.form("new_part_form", clear_on_submit=True):
        cA, cB, cC = st.columns([2,2,1])
        with cA:
            partNo = st.text_input("å“ç•ª *")
            description = st.text_input("å“å/ä»•æ§˜")
            category1 = st.text_input("ã‚«ãƒ†ã‚´ãƒª1")
            category2 = st.text_input("ã‚«ãƒ†ã‚´ãƒª2")
        with cB:
            unit = st.text_input("å˜ä½", value="set")
            unitPrice = st.number_input("å›ºå®šå˜ä¾¡ (é€šè²¨ä»»æ„)", min_value=0.0, step=100.0, value=0.0, format="%.2f")
            pricingModel = st.selectbox("ä¾¡æ ¼ãƒ¢ãƒ‡ãƒ«", options=["fixed","per_kwh","per_year"], index=0)
        with cC:
            unitPricePerKWh = st.number_input("å˜ä¾¡ (/kWh)", min_value=0.0, step=0.01, value=0.0, format="%.4f")
            unitPricePerYear = st.number_input("å˜ä¾¡ (/year)", min_value=0.0, step=100.0, value=0.0, format="%.2f")
            notes = st.text_area("å‚™è€ƒ", height=80)
        if st.form_submit_button("ä¿å­˜"):
            if not partNo.strip():
                st.warning("å“ç•ªã¯å¿…é ˆã§ã™")
            else:
                backup_db_file()
                row = pd.DataFrame([{
                    "partNo": partNo.strip(),
                    "description": description.strip(),
                    "manufacturer": "",
                    "category": "",
                    "unit": unit.strip() or "set",
                    "unitPrice": float(unitPrice) if unitPrice else None,
                    "notes": notes.strip(),
                    "category1": category1.strip(),
                    "category2": category2.strip(),
                    "pricingModel": pricingModel,
                    "unitPricePerKWh": float(unitPricePerKWh) if unitPricePerKWh else None,
                    "unitPricePerYear": float(unitPricePerYear) if unitPricePerYear else None,
                    "refCapacityKWh": None,
                }])[PART_COLS]
                n = insert_parts(row)
                st.success(f"{n} ä»¶ã‚’è¿½åŠ ã—ã¾ã—ãŸ")
                st.experimental_rerun()

    st.markdown("---")
    st.subheader("é¸æŠå‰Šé™¤ï¼ˆIDæŒ‡å®šï¼‰")
    part_id_to_delete = st.number_input("å‰Šé™¤ã™ã‚‹éƒ¨å“ID", min_value=0, step=1)
    if st.button("å‰Šé™¤å®Ÿè¡Œ"):
        try:
            backup_db_file()
            delete_part(int(part_id_to_delete))
            st.success("å‰Šé™¤ã—ã¾ã—ãŸ")
            st.experimental_rerun()
        except Exception as e:
            st.error(str(e))

with TAB_INGEST:
    st.subheader("ä¸€æ‹¬å–ã‚Šè¾¼ã¿ï¼ˆCSV/Excel/ãƒ†ã‚­ã‚¹ãƒˆï¼‰")
    if "pending_import" not in st.session_state:
        st.session_state["pending_import"] = None

    up = st.file_uploader("CSV ã¾ãŸã¯ Excel(xlsx) ã‚’é¸æŠ", type=["csv","xlsx"])
    if up is not None:
        if up.type == "text/csv" or up.name.lower().endswith(".csv"):
            df_raw = pd.read_csv(up)
        else:
            df_raw = pd.read_excel(up)
        st.write("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆå…ˆé ­20è¡Œï¼‰")
        st.dataframe(df_raw.head(20), use_container_width=True, height=300)

        st.markdown("### åˆ—ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆæœªæŒ‡å®šã¯ç©ºæ‰±ã„ï¼‰")
        all_cols = list(df_raw.columns)
        map_cols: Dict[str, str] = {}
        for key in PART_COLS:
            guessed = next((c for c in all_cols if guess_field(str(c)) == key), "")
            map_cols[key] = st.selectbox(f"{key}", options=[""]+all_cols, index=(all_cols.index(guessed)+1) if guessed in all_cols else 0, key=f"map_{key}")

        if st.button("ã“ã®è¨­å®šã§å–ã‚Šè¾¼ã¿å€™è£œã‚’ä½œæˆ"):
            df_norm = pd.DataFrame({k: (df_raw[map_cols[k]] if map_cols[k] else "") for k in PART_COLS})
            df_norm["partNo"] = df_norm["partNo"].astype(str).str.strip()
            df_norm = df_norm[df_norm["partNo"] != ""]
            for c in ["unitPrice","unitPricePerKWh","unitPricePerYear","refCapacityKWh"]:
                df_norm[c] = pd.to_numeric(df_norm[c], errors="coerce")
            df_norm["unit"] = df_norm["unit"].replace("", "set")
            df_norm["pricingModel"] = df_norm["pricingModel"].replace("", "fixed")
            st.session_state["pending_import"] = df_norm
            st.success("å–ã‚Šè¾¼ã¿å€™è£œã‚’ä½œæˆã—ã¾ã—ãŸã€‚ä¸‹ã§ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    st.markdown("---")
    st.markdown("### ãƒ†ã‚­ã‚¹ãƒˆè²¼ã‚Šä»˜ã‘è§£æï¼ˆPDF/ãƒ¡ãƒ¼ãƒ«ã‹ã‚‰ã‚³ãƒ”ãƒšå¯ï¼‰")
    txt = st.text_area("ã‚¿ãƒ– or 2ã‚¹ãƒšãƒ¼ã‚¹ä»¥ä¸ŠåŒºåˆ‡ã‚Š", height=160, placeholder="ä¾‹)\nSGCS-E30    EMS element â€“ Basic Functions ...")
    if st.button("è§£æã—ã¦å–ã‚Šè¾¼ã¿å€™è£œã‚’ä½œæˆ"):
        df = parse_free_text(txt)
        if df.empty:
            st.warning("è§£æã§ãã¾ã›ã‚“ã§ã—ãŸã€‚åˆ—åŒºåˆ‡ã‚Šï¼ˆã‚¿ãƒ–/2ã‚¹ãƒšãƒ¼ã‚¹ä»¥ä¸Šï¼‰ã§è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„ã€‚")
        else:
            st.session_state["pending_import"] = df
            st.success("å–ã‚Šè¾¼ã¿å€™è£œã‚’ä½œæˆã—ã¾ã—ãŸã€‚ä¸‹ã§ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    if st.session_state["pending_import"] is not None:
        st.markdown("---")
        st.subheader("å–ã‚Šè¾¼ã¿å€™è£œã®ç¢ºèª")
        dfp: pd.DataFrame = st.session_state["pending_import"]
        st.dataframe(dfp.head(100), use_container_width=True, height=360)
        confirm = st.checkbox("ã“ã®å†…å®¹ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆSQLite: parts_bom.dbï¼‰ã‚’æ›´æ–°ã—ã¦ã‚ˆã„")
        col_c1, col_c2 = st.columns(2)
        with col_c1:
            if st.button("âª å–ã‚Šè¾¼ã¿å€™è£œã‚’ç ´æ£„"):
                st.session_state["pending_import"] = None
                st.info("å–ã‚Šè¾¼ã¿å€™è£œã‚’ç ´æ£„ã—ã¾ã—ãŸã€‚")
        with col_c2:
            if st.button("âœ… ç¢ºå®šã—ã¦DBæ›´æ–°", disabled=not confirm):
                try:
                    backup_db_file()
                    n = insert_parts(dfp)
                    st.success(f"{n} ä»¶ã‚’DBã«åæ˜ ã—ã¾ã—ãŸ")
                    st.session_state["pending_import"] = None
                except Exception as e:
                    st.error(str(e))

with TAB_BOM:
    st.subheader("BOM é¸æŠ/ä½œæˆ")

    cB1, cB2 = st.columns([2,1])
    with cB1:
        bom_name = st.text_input("æ–°ã—ã„BOMå")
    with cB2:
        if st.button("ä½œæˆ"):
            if not bom_name.strip():
                st.warning("BOMåã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            else:
                backup_db_file()
                new_id = create_bom(bom_name.strip())
                st.success(f"BOMã‚’ä½œæˆã—ã¾ã—ãŸ (id={new_id})")
                st.experimental_rerun()

    df_boms = list_boms()
    st.dataframe(df_boms, use_container_width=True, height=180)

    target_bom_id = st.number_input("æ“ä½œå¯¾è±¡ã®BOM ID", min_value=0, step=1, value=int(df_boms.iloc[0]["id"]) if not df_boms.empty else 0)

    st.markdown("---")
    st.markdown("### é¸æŠæ¸ˆã¿éƒ¨å“ã‚’BOMã¸è¿½åŠ ")
    sel_ids = st.session_state.get("selected_part_ids", [])
    st.write(f"é¸æŠä¸­ã®éƒ¨å“ID: {sel_ids}")
    if st.button("é¸æŠè¡Œã‚’BOMã«è¿½åŠ "):
        if not sel_ids:
            st.warning("DBã‚¿ãƒ–ã§éƒ¨å“ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚")
        elif target_bom_id <= 0:
            st.warning("BOM ID ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            for pid in sel_ids:
                add_item(int(target_bom_id), int(pid), qty=1.0)
            st.success(f"{len(sel_ids)} ä»¶ã‚’BOM({target_bom_id})ã¸è¿½åŠ ã—ã¾ã—ãŸã€‚")

    st.markdown("---")
    st.subheader("BOM æ˜ç´°ï¼ˆå®¹é‡ãƒ»å¹´æ•°ã‚’åæ˜ ï¼‰")

    st.markdown("#### è¦‹ç©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
    colp1, colp2, colp3 = st.columns(3)
    with colp1:
        proj_kwh = st.number_input("å¯¾è±¡å®¹é‡ (kWh)", min_value=0.0, step=100.0, value=0.0)
    with colp2:
        proj_years = st.number_input("å¥‘ç´„å¹´æ•° (years)", min_value=0.0, step=1.0, value=0.0)
    with colp3:
        override_rate = st.number_input("EMSç­‰ã®kWhå˜ä¾¡ã‚’ä¸€æ™‚ä¸Šæ›¸ãï¼ˆä»»æ„ï¼‰", min_value=0.0, step=0.01, value=0.0, help="0 ã®ã¾ã¾ãªã‚‰DBå€¤ã‚’ä½¿ç”¨")

    if target_bom_id > 0:
        df_items = list_bom_items(int(target_bom_id))
        if not df_items.empty:
            df = df_items.copy()
            df["displayUnitPrice"] = df["unitPrice"]
            if "unitPricePerKWh" in df.columns:
                per_mask = df["pricingModel"].astype(str).str.lower().eq("per_kwh") & (proj_kwh > 0)
                base_rate = df["unitPricePerKWh"]
                if override_rate > 0:
                    base_rate = override_rate
                df.loc[per_mask, "displayUnitPrice"] = (base_rate * proj_kwh).round(2)
            if "unitPricePerYear" in df.columns:
                py_mask = df["pricingModel"].astype(str).str.lower().eq("per_year") & (proj_years > 0)
                df.loc[py_mask, "displayUnitPrice"] = (df.loc[py_mask, "unitPricePerYear"] * proj_years).round(2)

            df["amount"] = (df["displayUnitPrice"].fillna(0) * df["qty"].fillna(0)).round(0)
            total = int(df["amount"].sum())

            st.dataframe(df, use_container_width=True, height=380)
            st.write(f"**åˆè¨ˆ**: {total:,}")

            st.markdown("#### æ˜ç´°ç·¨é›†")
            item_id = st.number_input("æ›´æ–°å¯¾è±¡ itemId", min_value=0, step=1)
            new_qty = st.number_input("æ–°ã—ã„æ•°é‡", min_value=0.0, step=1.0, value=1.0)
            cc1, cc2 = st.columns(2)
            with cc1:
                if st.button("æ•°é‡æ›´æ–°"):
                    try:
                        backup_db_file()
                        update_qty(int(item_id), float(new_qty))
                        st.success("æ›´æ–°ã—ã¾ã—ãŸ")
                    except Exception as e:
                        st.error(str(e))
            with cc2:
                if st.button("æ˜ç´°å‰Šé™¤"):
                    try:
                        backup_db_file()
                        remove_item(int(item_id))
                        st.success("å‰Šé™¤ã—ã¾ã—ãŸ")
                    except Exception as e:
                        st.error(str(e))

            out_cols = ["partNo","description","category1","category2","unit","displayUnitPrice","qty","amount","notes"]
            export_df = df[out_cols].rename(columns={"displayUnitPrice":"unitPrice"})
            st.download_button(
                label="BOMã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=export_df.to_csv(index=False).encode("utf-8-sig"),
                file_name=f"bom_{int(target_bom_id)}.csv",
                mime="text/csv",
            )
            bio = io.BytesIO()
            with pd.ExcelWriter(bio, engine="openpyxl") as writer:
                export_df.to_excel(writer, index=False, sheet_name="BOM")
                pd.DataFrame([["","","","","","åˆè¨ˆ", "", total, ""]],
                             columns=["partNo","description","category1","category2","unit","unitPrice","qty","amount","notes"]
                            ).to_excel(writer, index=False, startrow=len(export_df)+2, sheet_name="BOM", header=False)
            st.download_button(
                label="BOMã‚’Excelã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=bio.getvalue(),
                file_name=f"bom_{int(target_bom_id)}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            )
        else:
            st.info("æ˜ç´°ãŒã‚ã‚Šã¾ã›ã‚“ã€‚DBã‚¿ãƒ–ã§éƒ¨å“ã‚’é¸ã³ã€ä¸Šã®ãƒœã‚¿ãƒ³ã§BOMã¸è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
    else:
        st.info("BOMã‚’é¸æŠ/ä½œæˆã—ã¦ãã ã•ã„ã€‚")

st.caption("SQLite/CSV/Excelå¯¾å¿œãƒ»ç¢ºèªä»˜ãå–ã‚Šè¾¼ã¿ãƒ»ã‚«ãƒ†ã‚´ãƒª1/2ãƒãƒ«ãƒãƒ•ã‚£ãƒ«ã‚¿ãƒ»ãƒã‚§ãƒƒã‚¯é¸æŠãƒ»per_kWh/per_yearè¨ˆç®—ãƒ»ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ­è¼‰ã€‚")
